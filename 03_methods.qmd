# Methodology {#sec-methods}

```{r setup1, file = "R/chapter_start.R", include = FALSE, cache = FALSE}

```

To evaluate longitudinal and bi-directional relationships between mental health and travel-activity while controlling for baseline conditions, we develop and analyze a unique dataset derived from a longitudinal study of mental health for a sample of university students, paired with mobile device location data for those students.
This section describes the origin of the data, how we processed the data and prepared it for analysis, and the econometric tools we employ in the analysis.

## Study Data

This research analyzed a unique dataset of 88 young adults who expressed suicidal ideation in therapy and subsequently enrolled in the study through the Brigham Young University (BYU) Counseling and Psychology Services (CAPS) program.
The enrollment process identified age and sex at birth from medical records.
The particpants self-reported their race, sex at birth and preferred gender identity.
This final value did not affect our analysis for the limited number of students whose gender identity did not match their sex at birth, and we discarded it from further evaluation.
A psychological evaluation measured each participant's intelligence quotient (IQ) and classified the participants into one of three neurotypology groups: those with autism spectrum disorder, those with social anxiety, or a final control group.
@tbl-descriptivestats gives a statistical description of the sample organized by neurotypology; The study included 28 individuals in the social anxiety group, 29 in the autism group, and 31 in the control group.

```{r table descripstats, message=FALSE, echo=FALSE, warning=FALSE}
#| label: tbl-descriptivestats
#| tbl-cap: "Descriptive Statistics by Group: Age, IQ Score, Sex, and Race"

tar_load(descrip_stats)

datasummary_balance(~Group, descrip_stats, dinm=FALSE, align = "llcccccc", 
                     output = "kableExtra", booktabs = TRUE) %>%
  kable_styling(latex_options="scale_down")
```

Participants installed an app on their phones that collected cellular LBS data, with some providing data for one month and others up to a year.
There was a one-month gap when no LBS data was collected.
In addition to LBS data, the app prompted participants to complete mental health surveys in the mornings and evenings, asking questions like, "Have you felt stressed since your last survey?" "How would you gauge your motivation?" and "Have you thought about killing yourself in the past 12 hours?" Participants were monetarily incentivized to complete the surveys.
By integrating LBS data and survey responses, we can analyze the interaction between travel behavior and mental health, especially in relation to the three groups.

## Data Curation

The raw LBS data included each participant's ID (userID), timestamp (date and time), and location coordinates (latitude and longitude).
The first step in data cleaning was to prepare the raw LBS data for further analysis by determining the activity day, applying a scoring algorithm, and refining the dataset.

To capture daily travel patterns more accurately, we shifted the traditional 24-hour period (typically ending at 11:59 PM) to span from 3:00 AM to 2:59 AM.
This adjustment ensured that any data points between 12:00 AM and 2:59 AM were classified as part of the previous dayâ€™s travel activities.
The data from this adjusted 24-hour window became the "activity day." Since the evening mental health survey closed at 3:00 AM, any surveys taken between 12:00 AM and 3:00 AM were linked to the preceding activity day, aligning travel and mental health data.

After establishing activity days and categorizing data points, we evaluated the
quality and completeness of the LBS data for each combination of userID and
activity day.  
In total, there were 12,051 userID-activity days with varying data quality.  
We implemented a scoring algorithm that categorized data by userID, activity
day, and hour, allowing us to identify high-quality LBS data.
The algorithm assigned scores based on the time of day and the number of LBS
points recorded, with higher scores given to daytime hours of significant activity and
greater LBS point counts.  

After removing low-scoring days, 4,405 out of 12,051 userID-activity days were
retained, meaning approximately 37% of days had LBS data of sufficient quality where
we could apply a DBSCAN-TE [@gongIdentificationActivityStop2018] algorithm to determine semantic activities 
--- where the person waited at a location for a substantive time. 
This algorithm classifies daily activities from a stream of location points by
grouping temporally and spatially clustered points, and then
separates activities at the same location at different times.
The DBSCAN-TE algorithm uses four parameters, which were optimized and applied
to the LBS data to identify activity locations for each userID-activity day; details on 
the optimization process are given in @macfarlaneClassifyingLocationPoints2024
and  @richesTransformingGPSPoints2022. 
The DBSCAN-TE algorithm generated results for 3,845 out of the 4,405 days with
sufficient points.

In addition to calculating the total number of activities for each
userID-activity day, we identified activities that occurred at four specific
location types: parks, grocery stores, libraries, and social recreation sites.
Using OpenStreetMap data, we created GeoJSON shapefiles for these locations in
Utah County and overlaid them with the spatial geometry of activities to
determine the number of activities at each specific location type.

Because we had quality activity-day data for only one in three days on average, and we only had
survey data for one in X days on average, it was difficult to get mood and motivation information
on the exact day for which we had travel data. To improve the matching, we
calculated a seven-day retrospective moving average of the existing data for the
number of activities, and the number of activities located at parks, libraries,
and social recreation sites.  After applying the rolling averages, we identified
5,673 userID-activity days for the seven-day rolling average. Completed
motivation surveys without a valid average activity-day within range were
discarded.

## Statistical Modeling

We build a regression model of motivation for individual $i$ at time period $t$
$$
\text{Motivation}_{it} = \alpha +  \vec{\beta} \vec{X}_{it}  + \mu_{it}
$$ {#eq-motivation}
where $\alpha$ is an estimated mean-effect intercept, $\mu$ is a regression residual, 
$\vec{\beta}$ a vector of estimable parameters, and the vector of explanatory variables $X$ contains individual and activity 
descriptors,
$$
X = 
\begin{cases} 
\text{individual descriptors}_i \\
\text{number of activities}_{it} \\
\text{moving avg. number of activities}_{i(t-t_7)} \\
\text{activities at locations}_{it} \\
\end{cases}
$$ {#eq-variables}

Motivation, reported in daily evening surveys on a scale from 0-100, serves as the dependent variable.
Participants used a drag bar to indicate the motivation they experienced that day, with the levels described as:

  - **0-19** "None at all or little motivation"
  - **20-39** "Enough motivation to get by"
  - **40-59** "Typical motivation"
  - **60-79** "Plenty of motivation"
  - **80-100** "Unusually high motivation feeling hyper or even agitated at times".
The level of motivation is used as a measure for overall well-being, with higher scores implying more motivation.

Two important econometric issues can arise with this model. The first is the question of individual effects; some
study participants will have a higher or lower baseline motivation than others, which can
interfere with our ability to estimate the effect of travel on motivation. We address this issue by 
using fixed effects (FE) and random effects (RE) models, which we describe in detail below. The second issue is 
with serial autocorrelation, where an individual's high motivation on one day may lead to high motivation on the next day. This 
interferes with the model's estimate of the standard error. We address this issue using autocorrelation-robust
standard errors and again describe the details below. We estimate the model parameters and standard errors
using functions in the `plm` package for R [@plm].


### Fixed and Random Effects Regression

The model presented in @eq-motivation is a standard model that can be estimated by ordinary least squares (OLS). 
For linear regressions, OLS requires assumptions that the error terms are
independently and identically distributed (IID) with a normal distribution of
mean 0. There are two common econometric techniques, known as FE and RE, that attempt to account for these baseline measures, which are discussed in the following sections.

The FE model, also called the within transformation, demeans the data by
participant and looks at each participant's levels of motivation and seven-day
rolling average number of activities individually.  This results in having
different intercepts for each participant.
@eq-fe shows the base equation for the FE model 
$$
y_{it} - \bar{y}_i = \beta ( x_{it} - \bar{x}_i ) + \mu_{it} -\bar{\mu}_i 
$$ {#eq-fe} 
One consequence of this transformation is that time-invariant data --- such as 
any demographic information relating to the indviual $i$ --- is removed, or rather their
cumulative effects are absorbed by the individual-level intercept.
The FE model is unbiased and removes all individual effects, but less efficient
because it results in losing degrees of freedom to estimate individual
intercepts for each participant. This results in larger standard errors for the
estimates which can make it more difficult to recognize significance.

The RE model semi-demeans the data by participant.
Based on a mean for the entire group, a mean is determined with a set standard deviation to represent the data of the entire group.
The RE model assumes that $\alpha_i$, the unobserved effect, is uncorrelated with the seven-day rolling average number of activities.
$\lambda$ represents a "transformation that eliminates serial correlation in the errors" [@wooldridgeIntroductoryEconometricsModern2009, pg. 490].
$$ 
y_{it}-\lambda\bar{y}_i = \beta_0(1-\lambda)+\beta_1 ( x_{it1}-\lambda\bar{x}_{i1})+...+\beta_k (x_{itk}-\lambda\bar{x}_{ik})+(\nu_{it}-\lambda\bar{\nu}_i) 
$$ {#eq-re}
The RE model is appropriate to use if it is believed that the difference in
motivation has an influence on the seven-day rolling average number of
activities; it is also more efficient because fewer parameters require estimation.
It is possible, however, that other variables that influence the seven-day rolling average
number of activities are not included which can lead to bias in the model. A Hausmann test
between the FE and RE results can identify whether the RE estimates are consistent with the FE
estimates, and which model is therefore preferred.

### Autocorrelation and Heteroskedasticity

When analyzing how motivation changes over time for individual people, autocorrelation and heteroskedasticity can arise as statistical challenges.
Autocorrelation occurs when observations in a time series are correlated with preceding or succeeding observations, violating the assumption of independence between observations.
In the context of studying individual motivation over time, autocorrelation can manifest as a person's motivation level at one point in time being influenced by their motivation level at previous time points.
This can lead to biased estimates and inflated significance levels in regression analyses.
Heteroskedasticity refers to the unequal variance of errors across observations in a dataset.
In the case of studying motivation over time, heteroskedasticity may arise if the variability in motivation levels differs between individuals or varies systematically over time.
This violates the assumption of homoscedasticity, where the variance of the errors remains constant across observations, impeding statistical inference.
Autocorrelation and heteroskedasticity can impede statistical inference underestimating the residuals. 
In this study, we employ Heteroskedasticity and Autocorrelation Consistent (HAC) robust standard error estimates. 
HAC robust standard errors are particularly useful when dealing with time series or panel data where observations may be correlated across time periods.
HAC estimators adjust for heteroskedasticity by allowing the variance of the errors to vary across observations.
However, they also account for autocorrelation by incorporating a weighting scheme that considers the correlation structure of the data over time.
This weighting scheme assigns higher weights to more recent observations and lower weights to distant observations, reflecting the diminishing influence of past observations on current ones.
