## Findings
```{r setup, file = "R/chapter_start.R", include = FALSE}
# a number of commands need to run at the beginning of each chapter. This
# includes loading libraries that I always use, as well as options for 
# displaying numbers and text.
```

```{r setup2, include = FALSE, cache = FALSE}
# Other packages ------
# These are packages that get used in this chapter but aren't part of the default set.
theme_set(theme_bw())

modes <- function(d){
    i <- which(diff(sign(diff(d$y))) < 0) + 1
    data.frame(x = d$x[i], y = d$y[i])
}


get_mode <- function(d){
    i <- which.max(d$y)
    d$x[i]
}

```


```{r sann_results}
#| label: tbl-sann-results
#| tbl-cap: Simulated Annealing Results
tar_load(sann_results)
pt <- bind_rows(
  sann_results$params |> 
    mutate(run = as.character(1:4)),
  sann_results$params |> 
    ungroup() |> 
    summarise(across(radius:entrop, ~mean(.))) |> 
    mutate(run = "MEAN")
) |> 
  rename(
    `$\\rho$`     = minpts,
    `$\\Delta T$` = deltat,
    `$\\varepsilon$` = radius,
    `$\\tau$` = entrop,
    `Error` = error,
    `Run` = run
  )
kbl(pt, booktabs = TRUE, escape = FALSE, digits = 2) |> 
  kable_styling()
```

We ran the simulated annealing algorithm for 5000 iterations, beginning with 
four randomly sampled sets of starting values. @tbl-sann-results
shows the results of each run alongside a mean value. For most
parameters, there is some level of agreement on the scale of the parameters,
with three of the four runs matching in the first or second significant
digit. The anomalous value differs between runs however, as Run 3 has a
low $\rho$, and Run 4 a low $\tau$.

```{r sann-function}
#| label: fig-sann-function
#| fig-cap: "Value of objective function, averaged across last 1000 iterations."
#| fig-width: 9
#| fig-height: 5
sann_results$run_list |> 
  filter(error< 1.5) |> 
  mutate(
    run = factor(run, labels = 1:4),
    radius = plyr::round_any(radius, 5),
    minpts = plyr::round_any(minpts, 10)
  ) |> 
  group_by(run, radius, minpts) |> 
  summarise(Error = mean(error)) |> 
  ungroup() |> 
  ggplot(aes(x = minpts, fill = Error, y = radius)) + 
  geom_tile()  +
  facet_wrap(~run) +
  scale_fill_viridis_c(option = "inferno", direction = -1) + 
  xlab("$\\rho$ - Minimum points") + 
  ylab("$\\varepsilon$ - Radius")
```

```{r sann-outcomes, warning=FALSE}
#| label: fig-sann-outcomes
#| fig-cap: "Distribution of lowest error simulated annealing parameters."
#| fig-width: 9
#| fig-height: 5
ethld <- 1.31
sr <- sann_results$run_list|> 
  filter(error < ethld) |> 
  select(-iteration) 

# get modes
dl <- sr |> 
  select(-run) |> 
  pivot_longer(radius:entrop) |> 
  group_by(name) |> 
  nest()  |> 
  mutate(
    density = purrr::map(data, \(x) density(x$value, weights = 1/(x$error))),
    max     = purrr::map_dbl(density, \(d) get_mode(d)),
    modes   = purrr::map(density, \(d) modes(d))
  )

sr |> 
  rename(
    `$\\rho$`     = minpts,
    `$\\Delta T$` = deltat,
    `$\\varepsilon$` = radius,
    `$\\tau$` = entrop
  ) |> 
  pivot_longer(cols = c(-run, -error)) |> 
  ggplot(aes(x = value, weight = 1/(error))) +
  geom_density() + 
  facet_wrap(~name, scales = "free")
```

@fig-sann-function shows the mean value of the error function 
across the parameters $(\rho, \varepsilon)$. If a cell is blank, then
the simulated annealing algorithm did not search there, or the error
exceeded 1.5. This figure only shows two dimensions of the four in the
objective function, so there is variance at each $(\rho, \varepsilon)$ 
coordinate. Nevertheless, the plot shows consistently lower error 
for low $\varepsilon$ and $\rho \approx 200$.
@fig-sann-outcomes shows a density of each parameter across all four runs with 
$E < `r ethld`$.
The results of `r nrow(sr)` iterations are included.
The distribution is weighted by the inverse error, $w_j = 1/E_j$
with $j$ an index for the optimization iteration.
Other weight constructions did not result in substantially different interpretations of 
this figure. The modes of this density plot 
$\{\varepsilon = `r dl$max[1]` \mathrm{\ m}, \rho = `r dl$max[2]`\mathrm{\ points}, \Delta T = `r dl$max[3]`\mathrm{\ s}, \tau = `r dl$max[4]`\}$ are candidates for the preferred values.

A different error function could be developed that includes not only the location
but the duration of activities, and their sequence in a time-space 
framework. This would improve the accuracy of the calibration but also 
increases the difficulty of the labeling task. Similarly, data with a different
temporal or spatial resolution may lead to different optimal parameters.

